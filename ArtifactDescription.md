# Artifact Description

## 概要：e-desk

以下，記述事項の説明．

* 改変対象OSS:[e-desk](https://github.com/ryusuke-m/e-desk)
  + プロジェクターとカメラ(webカメラもしくは深度カメラ)を用いたプロジェクションアプリ
  + 机の上を丸ごと電子書籍のように扱えるようにすることを目的とする．
    + 具体的にはオープンソースの画像処理ライブラリ[OpenCV](https://opencv.org)標準のARマーカを用いて，机の四隅を認識し，(ARマーカの印刷された)紙面上に電子書籍コンテンツを投影する．
      + 投影する際には，ARマーカの位置(=紙の傾き)を見て，正しく投影されるように映像を射影変換する．
    + また，オープンソースの物体検出・画像分割エンジン[YOLO](https://docs.ultralytics.com/ja)を利用したハンドジェスチャーによって，コンテンツを操作する．
* 改変内容「シミュレーションモードの実装」
  + シミュレーションモードを実装
  + プロジェクターが無い状態でも起動，仮想的な動作を可能にする．
    + また，X Window System互換のシステムが実装されていない場合でもシミュレーション動作が可能．
  + あくまで動作であり，完全な動作を可能にするわけではない．
    + 動画への対応が出来ていない．
  + また，映像出力については，出力された画像をDocker上で立てたサーバから確認できる．

## クイックスタート

```
docker pull watson9109/2024-t2201411-e-desk
docker run -p -p 8000:8000 --rm watson9109/e-desk:latest 
```

### シミュレーションモードの結果を見る場合
画像表示の為にローカルにサーバを立てる必要がある．
```
python3 pythonserver.py
```
https://localhost:8080 にアクセスすることで結果が確認できる．

### 仮想カメラとして入力する画像の作成
```
python3 GenAR.py
```
仮想カメラの入力としてVirtualDesk.pyが作成される．

### シミュレーションモードの再実行
```
python3 Start.py
```

シミュレーションは仮想カメラを利用すること以外通常の起動と同じ挙動をすることから，自動で終了しない．
以下の出力が確認できたら，`Ctrl+C`等で終了させること．その際に出力されるエラーは無視してよい．

```
0: 384x640 (no detections), 40.0ms
Speed: 1.2ms preprocess, 40.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)
```

## 評価手順

以下，記述事項の説明．

* 
* (あれば)ウェブカメラからの映像が表示出来ているか．
* Dockerコンテナ起動時，上記クイックスタートの実行時にエラーが発生した場合は，その内容を書いていただけると幸い．

## 制限と展望

以下，記述事項の説明．
* カメラ入力について
  * 時間等の都合でカメラ入力として，あらかじめ作成した画像を利用するような形とした．
  * Webカメラ，内蔵カメラからの映像処理は行わなかった．
    + [Docker Community Forum](https://forums.docker.com/t/how-to-use-a-host-usb-device-in-a-container-in-docker-desktop/138905)によると，WindowsもしくはOSXでは，LinuxVM下で動かす必要があるらしい．
    + 各環境によってUSBデバイスの引数が変わりうる為，簡単な評価が提供できないことから行わなかった．
  * WebRTCを用いてカメラ入力を取ってくることは時間に余裕があれば行いたかった．
    + WebRTCを用いて，ローカルに立てたサーバにHTTPSで映像の受送信を行うことも考えた．
    + TypeScriptでWebRTC関連の処理を実装する必要があり，時間が足りず，十分な動作を保証出来なかった為，実装を諦めた．
    + ネットワーク上での映像のやり取りには興味があるので，暇があればやろうと思う．
* 映像出力について
  * Dockerで映像出力を行うためには，現在ディスプレイを管理しているX Window System互換のサーバを渡す必要がある．
  * カメラ入力同様に簡単な評価が提供できないことから行わなかった．
  * WebRTCについても同様．  
* Dockerイメージの肥満(8GBもある!!)
  + OpenCV，YOLO等画像処理ライブラリ，モデルが入っている為もあり，Dockerイメージが肥えている．
  + マルチステージングや，slimイメージをベースにする，画像認識モデルをより小さくすることが必要．
* プロセスを作った後，安全に終了するようになっていない．
  + 実行の後はDockerのコンテナ丸ごと消去するだろうという考えの為
  + 本来なら安全にプロセスを終了できるようにすべきだった．(時間不足)
## 更なる使い方（オプション）

* 現在は仮想カメラからの画像，映像の処理を行うことができる．
  * エンドユーザよりも，開発時の利用が主となる．
    * 事前に撮影した映像，画像の処理を確認できる．
    * 例えば，一部処理を書き換えた際の映像処理の差異を確認できる．
* また，現在は実装出来ていないが，WebRTCを用いた仮想カメラの実装ができればエンドユーザ向けの利用も可能になる．
  * サーバへの処理の委託
    * サーバに画像認識等の重い処理を任せられるようになる為，デバイスの取り回しが良くなる．
    * プロジェクタ側はHTTPを処理でき，カメラとプロジェクタを取り付けるだけで良くなる．